---
layout: post
title: "CELP â€” Kaggle Data Challenge"
subtitle: "Competition recap and final result"
date: 2024-02-22 09:00:00
categories: [data-science, machine-learning, competition]
---

In a team of 3, I participated in the Kaggle competition "CELP" (overview: https://www.kaggle.com/competitions/celp), a focused data challenge that attracted a wide range of approaches from the community.

The competition required teams to design data-driven solutions that addressed the task definition and evaluation protocol provided on the Kaggle page. Successful teams combined careful preprocessing, strong modeling choices and evaluation-time engineering to meet the benchmark objectives.

Our work on CELP emphasised solid data preprocessing, robust model selection and ensembling. In practice we:

- Normalised and cleaned the input features to reduce distributional shifts.
- Trained multiple model architectures and selected checkpoints with stable validation behaviour.
- Applied ensembling and lightweight postprocessing at inference to improve final scores.

The competition invited many modeling styles and required attention to both validation strategy and evaluation-time details. After iterative development and leaderboard-focused tuning, our final submission achieved the best score on the competition's final leaderboard. Securing first place validated our end-to-end approach and engineering choices.

See the official competition page for full details, rules and datasets:

- https://www.kaggle.com/competitions/celp
